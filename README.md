##Collections

This repo is a collection of small projects and investigations. For the most part, these projects were completed as part of coursework, though not exclusively. I have denoted in each case when the work was not my own. Below is brief summary of items that may be found here.
 I also have a repo for a current independent project, [hetaira](https://github.com/mhonaker/hetaira).

* **graphs1.py**
    A collecttion of standard graph data structure construction and analysis routines, written in python. Included are methods to construct fully complete graphs, canonical ER graphs, and DPA graphs. Or text files representing grahs can be loaded. The distributions of node and in-degrees were also examined.

* **graphs2.py**
    Extends the first set of graph functions to include UPA graphs, BFS searching though graph structures, finding closest connected nodes, and simulating targeted and random node removal.

* **clustering.py**
    Examples of hierarchical and k-means clustering algorithms, inclusding a test of two algortihms for finding closest pairs. Th alg_cluster.py module was associated with project and was *not* written by me.

* **sequence_alignment.py**
    Contains an implementation of the Needleman-Wunsch algorithm, and demonstrations of both local and global sequence alignments.

* **twitter_analysis.py**
    This file contains the code used for a project whereupon I comleted a light analysis of some Twitter data scraped from the live feed using the Twitter API. The associated twittersteam.py was *not* written by me.

* **MapReduceAnswers.py**
    Located hereis the python code used to complete a small project using the MapReduce framework. This was run on top of the associated MapReduce.py, which was also *not* written by me.

* **SQLAssignment.md**
    This is a listing of the SQL querys performed to answer each question as listed.

* **hadoop.md**
    Similiar to the SQL assigment, this fil also contains the qestions asked, and the commands given to answer them. In this case, 550 GB, and 0.5 TB datsets were examined using hadoop clusters created on AWS EC2 instances. PIG was used to actually perform the analyses.

* **machine_learning.py**
    A set of functions in python that recapitulate similar function originally written in Octave for a class in machine learning. Regression (logistic and linear), neural networks, k-means, and PCA are all included. The associated testing file was used to test these functions.

* **The Rest**
    Also in this repo are several folders, these are groups of Octave functions completed for a machine learing class. In all cases, the support code was provided by the instructors, and my code is clearly labeled as such. There are also some examples of markdown documents which were the result of R based machine learning and data analysis projects for classes.

I have not, in general, included any of the datafiles used for testing or analysis.

